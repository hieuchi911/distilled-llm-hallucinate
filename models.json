[
    {
        "task_name": "qa",
        "datasets": [
            {"name": "hotpot_qa", "hf_path": "hotpot_qa", "subset": "distractor", "split": "validation"},
            {"name": "truthful_qa", "hf_path": "truthful_qa", "subset": "generation", "split": "validation"}
        ],
        "models": [
            {
                "language_model": "Nicolas-BZRD/pythia-1b-deduped_pubmed_qa_Llama-2-7b-chat-hf_text_teacher",
                "tokenizer": "EleutherAI/pythia-1b-deduped"
            },
            {
                "language_model": "Nicolas-BZRD/bloomz-560m_pubmed_qa_Llama-2-7b-chat-hf_text_teacher",
                "tokenizer": "bigscience/bloomz-560m"
            },
            {
                "language_model": "Nicolas-BZRD/mt0-base_pubmed_qa_Llama-2-7b-chat-hf_text_teacher",
                "tokenizer": "bigscience/mt0-base"
            },
            {
                "language_model": "Nicolas-BZRD/opt-350m_pubmed_qa_Llama-2-7b-chat-hf_text_teacher",
                "tokenizer": "facebook/opt-350m"
            },
            {
                "language_model": "Nicolas-BZRD/pythia-1b-deduped_pubmed_qa_Llama-2-7b-chat-hf_uld_loss",
                "tokenizer": "EleutherAI/pythia-1b-deduped"
            },
            {
                "language_model": "Nicolas-BZRD/bloomz-560m_pubmed_qa_Llama-2-7b-chat-hf_uld_loss",
                "tokenizer": "bigscience/bloomz-560m"
            },
            {
                "language_model": "Nicolas-BZRD/mt0-base_pubmed_qa_Llama-2-7b-chat-hf_uld_loss",
                "tokenizer": "bigscience/mt0-base"
            },
            {
                "language_model": "Nicolas-BZRD/opt-350m_pubmed_qa_Llama-2-7b-chat-hf_uld_loss",
                "tokenizer": "facebook/opt-350m"
            }
        ]
    },
    {
        "task_name": "summ",
        "datasets": [
            {"name": "cnn_dm", "hf_path": "cnn_dailymail", "subset": "1.0.0", "split": "validation"}
        ],
        "models": [
            {
                "language_model": "Nicolas-BZRD/pythia-410m-deduped_dialogsum_Mistral-7B-Instruct-v0.2_text_teacher",
                "tokenizer": "EleutherAI/pythia-1b-deduped"
            },
            {
                "language_model": "Nicolas-BZRD/bloomz-560m_dialogsum_Mistral-7B-Instruct-v0.2_text_teacher",
                "tokenizer": "bigscience/bloomz-560m"
            },
            {
                "language_model": "Nicolas-BZRD/mt0-base_dialogsum_Mistral-7B-Instruct-v0.2_text_teacher",
                "tokenizer": "bigscience/mt0-base"
            },
            {
                "language_model": "Nicolas-BZRD/opt-350m_dialogsum_Mistral-7B-Instruct-v0.2_text_teacher",
                "tokenizer": "facebook/opt-350m"
            },
            {
                "language_model": "Nicolas-BZRD/pythia-410m-deduped_dialogsum_Mistral-7B-Instruct-v0.2_uld_loss",
                "tokenizer": "EleutherAI/pythia-1b-deduped"
            },
            {
                "language_model": "Nicolas-BZRD/bloomz-560m_dialogsum_Mistral-7B-Instruct-v0.2_uld_loss",
                "tokenizer": "bigscience/bloomz-560m"
            },
            {
                "language_model": "Nicolas-BZRD/mt0-base_dialogsum_Mistral-7B-Instruct-v0.2_uld_loss",
                "tokenizer": "bigscience/mt0-base"
            },
            {
                "language_model": "Nicolas-BZRD/opt-350m_dialogsum_Mistral-7B-Instruct-v0.2_uld_loss",
                "tokenizer": "facebook/opt-350m"
            }
        ]
    }
]